{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Madhukar/opt/miniconda3/envs/ee_skmr/bin/python\n",
      "3.9.2 | packaged by conda-forge | (default, Feb 21 2021, 05:02:20) \n",
      "[Clang 11.0.1 ]\n",
      "sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "technical-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mental-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the nhd addendum file\n",
    "nhd_stats = pd.read_csv(\"nhd_stats_AI.csv\")\n",
    "\n",
    "# read in csv file with SSURGO variables\n",
    "df_m = pd.read_csv(\"combined_regular_clean_with_ssurgo_variables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liable-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # comid's from GEE are extracted into several pickled files\n",
    "# # pickling is needed to be able to share easily across team members \n",
    "# # join these pickled files into one full dataset\n",
    "\n",
    "# df_merged_full = []\n",
    "\n",
    "# for i in range(df_m.shape[0] // 500 + 1):\n",
    "#     try:\n",
    "#         df_temp = pd.read_pickle(('NHD_extracted_vars_2.5kmX2.5km/combined_regular_clean_with_ssurgo_nhd_variables_part' + \n",
    "#                               str(500 * i + 1)))\n",
    "        \n",
    "#     except:\n",
    "#         break\n",
    "#     df_merged_full.append(df_temp)\n",
    "# df_merged_full = pd.concat(df_merged_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extraordinary-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to protocol 3 so that can read in aws\n",
    "# df_merged_full = []\n",
    "\n",
    "# for i in range(df_m.shape[0] // 500 + 1):\n",
    "#     try:\n",
    "#         df_temp = pd.read_pickle(('NHD_extracted_vars_2.5kmX2.5km/combined_regular_clean_with_ssurgo_nhd_variables_part' + \n",
    "#                               str(500 * i + 1)))\n",
    "#         print(df_temp.shape)\n",
    "#         pickle.dump(df_temp, open(\"NHD_extracted_vars_2.5kmX2.5km/combined_regular_clean_with_ssurgo_nhd_variables_part\" + str(500 * i + 1) + \"_pkl3.pkl\",\"wb\"), protocol=3)\n",
    "#         df_temp2 = pd.read_pickle(('NHD_extracted_vars_2.5kmX2.5km/combined_regular_clean_with_ssurgo_nhd_variables_part' + \n",
    "#                               str(500 * i + 1)))\n",
    "\n",
    "#     except:\n",
    "#         break\n",
    "#     df_merged_full.append(df_temp2)\n",
    "# df_merged_full = pd.concat(df_merged_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infrared-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write this df into pickle\n",
    "# import pickle\n",
    "# pickle.dump(df_merged_full, open(\"NHD_extracted_vars_2.5kmX2.5km/combined_regular_clean_with_ssurgo_nhd_variables_partsmerged_pk3.pkl\",\"wb\"), protocol=3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-distributor",
   "metadata": {},
   "source": [
    "# Read in merged pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conditional-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_full = pd.read_pickle(\"200mX200m_nhd_variables_partsmerged_pk3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adult-revelation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'jurisdiction_type', 'da_number',\n",
       "       'district', 'project_name', 'longitude', 'latitude',\n",
       "       'date_issued_or_denied', 'rha_determination', 'cwa_determination',\n",
       "       'rha1', 'rha2', 'cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6', 'cwa7',\n",
       "       'cwa8', 'cwa9', 'potential_wetland', 'index', 'Index', 'mukey',\n",
       "       'hydclprs', 'aws025wta', 'drclassdcd', 'nhd_vars_wb', 'nhd_vars_fl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-title",
   "metadata": {},
   "source": [
    "# A word on 'nhd_vars_wb' and 'nhd_vars_fl' columns (see last two columns above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-gamma",
   "metadata": {},
   "source": [
    "## nhd_vars_wb: this is a list of lists\n",
    "- for each record, the following six features from GEE are extracted as lists and stored into a list\n",
    "- [comid_list, ftype_str, gnis_id, wb_area, fl_length, fcode]\n",
    "- the column is labeled nhd_vars_wb for waterbodies\n",
    "\n",
    "In a similar fashion, there is another column for flowlines labeled nhd_vars_fl\n",
    "\n",
    "Note: fl_length is NaN's for waterbodies and wb_area ae NaN's for flowlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-investor",
   "metadata": {},
   "source": [
    "## In the following, features are extracted from the above columns and feature engineered as discussed in meetings. Pls use your judgement to help devise any new features you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prescribed-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wb for waterbodies\n",
    "# extract the individual lists\n",
    "df_merged_full[\"wb_comid_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_wb[0], axis=1)\n",
    "df_merged_full[\"wb_ftype_str_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_wb[1], axis=1)\n",
    "df_merged_full[\"wb_gnis_id_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_wb[2], axis=1)\n",
    "df_merged_full[\"wb_area_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_wb[3], axis=1)\n",
    "\n",
    "# fl for flowlines\n",
    "# extract the individual lists\n",
    "df_merged_full[\"fl_comid_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_fl[0], axis=1)\n",
    "df_merged_full[\"fl_ftype_str_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_fl[1], axis=1)\n",
    "df_merged_full[\"fl_gnis_id_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_fl[2], axis=1)\n",
    "df_merged_full[\"fl_length_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_fl[4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-continent",
   "metadata": {},
   "source": [
    "# Lets look at columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "level-catalog",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nhd_vars_wb</th>\n",
       "      <th>nhd_vars_fl</th>\n",
       "      <th>wb_comid_list</th>\n",
       "      <th>wb_ftype_str_list</th>\n",
       "      <th>wb_gnis_id_list</th>\n",
       "      <th>wb_area_list</th>\n",
       "      <th>fl_comid_list</th>\n",
       "      <th>fl_ftype_str_list</th>\n",
       "      <th>fl_gnis_id_list</th>\n",
       "      <th>fl_length_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([120052831], [LakePond], [974076], [171.202],...</td>\n",
       "      <td>([21980217, 21978365], [ArtificialPath, Stream...</td>\n",
       "      <td>[120052831]</td>\n",
       "      <td>[LakePond]</td>\n",
       "      <td>[974076]</td>\n",
       "      <td>[171.202]</td>\n",
       "      <td>[21980217, 21978365]</td>\n",
       "      <td>[ArtificialPath, StreamRiver]</td>\n",
       "      <td>[, ]</td>\n",
       "      <td>[3.135, 3.557]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>([], [], [], [], [], [])</td>\n",
       "      <td>([], [], [], [], [], [])</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>([904140246], [LakePond], [970427], [6693.837]...</td>\n",
       "      <td>([21632389, 21635913], [Coastline, Coastline],...</td>\n",
       "      <td>[904140246]</td>\n",
       "      <td>[LakePond]</td>\n",
       "      <td>[970427]</td>\n",
       "      <td>[6693.837]</td>\n",
       "      <td>[21632389, 21635913]</td>\n",
       "      <td>[Coastline, Coastline]</td>\n",
       "      <td>[, ]</td>\n",
       "      <td>[1.895, 10.109]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>([], [], [], [], [], [])</td>\n",
       "      <td>([], [], [], [], [], [])</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>([], [], [], [], [], [])</td>\n",
       "      <td>([15560261], [CanalDitch], [], [nan], [0.95], ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[15560261]</td>\n",
       "      <td>[CanalDitch]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>([], [], [], [], [], [])</td>\n",
       "      <td>([], [], [], [], [], [])</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          nhd_vars_wb  \\\n",
       "9   ([120052831], [LakePond], [974076], [171.202],...   \n",
       "10                           ([], [], [], [], [], [])   \n",
       "11  ([904140246], [LakePond], [970427], [6693.837]...   \n",
       "12                           ([], [], [], [], [], [])   \n",
       "13                           ([], [], [], [], [], [])   \n",
       "14                           ([], [], [], [], [], [])   \n",
       "\n",
       "                                          nhd_vars_fl wb_comid_list  \\\n",
       "9   ([21980217, 21978365], [ArtificialPath, Stream...   [120052831]   \n",
       "10                           ([], [], [], [], [], [])            []   \n",
       "11  ([21632389, 21635913], [Coastline, Coastline],...   [904140246]   \n",
       "12                           ([], [], [], [], [], [])            []   \n",
       "13  ([15560261], [CanalDitch], [], [nan], [0.95], ...            []   \n",
       "14                           ([], [], [], [], [], [])            []   \n",
       "\n",
       "   wb_ftype_str_list wb_gnis_id_list wb_area_list         fl_comid_list  \\\n",
       "9         [LakePond]        [974076]    [171.202]  [21980217, 21978365]   \n",
       "10                []              []           []                    []   \n",
       "11        [LakePond]        [970427]   [6693.837]  [21632389, 21635913]   \n",
       "12                []              []           []                    []   \n",
       "13                []              []           []            [15560261]   \n",
       "14                []              []           []                    []   \n",
       "\n",
       "                fl_ftype_str_list fl_gnis_id_list   fl_length_list  \n",
       "9   [ArtificialPath, StreamRiver]            [, ]   [3.135, 3.557]  \n",
       "10                             []              []               []  \n",
       "11         [Coastline, Coastline]            [, ]  [1.895, 10.109]  \n",
       "12                             []              []               []  \n",
       "13                   [CanalDitch]              []           [0.95]  \n",
       "14                             []              []               []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_full[df_merged_full.columns[29:39]][9:15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-privilege",
   "metadata": {},
   "source": [
    "## Lets look at one row in individual columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extra-gamma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([120052831], ['LakePond'], ['974076'], [171.202], [nan], [39004])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at waterbodies list\n",
    "df_merged_full.nhd_vars_wb[9]\n",
    "# you can see there are 6 items in the list [comid_list, ftype_str, gnis_id, wb_area, fl_length, fcode]\n",
    "# note that fcode is going to be null due to coding lapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "peripheral-advancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([21980217, 21978365],\n",
       " ['ArtificialPath', 'StreamRiver'],\n",
       " ['', ''],\n",
       " [nan, nan],\n",
       " [3.135, 3.557],\n",
       " [55800, 46006])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at flowlines list\n",
    "df_merged_full.nhd_vars_fl[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "activated-wallet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[120052831]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of comids in waterbodies\n",
    "df_merged_full.wb_comid_list[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "altered-mandate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21980217, 21978365]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of comids in flowlines\n",
    "df_merged_full.fl_comid_list[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-future",
   "metadata": {},
   "source": [
    "### .... and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "continued-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Filter out invalid comids (although not used in this notebook)\n",
    "# # \"invalid\" = present in GEE but not present in nhd_stats\n",
    "\n",
    "# df_merged[\"wb_comid_list_filtered\"] = df_merged.apply(lambda x: [comid for comid in x.nhd_vars_wb[0] if comid in np.array(nhd_stats.comid)\n",
    "#                                                                 ], axis=1)\n",
    "\n",
    "# df_merged[\"fl_comid_list_filtered\"] = df_merged.apply(lambda x: [comid for comid in x.nhd_vars_fl[0] if comid in np.array(nhd_stats.comid)\n",
    "#                                                                 ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "immune-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigned begin and end of records for each person\n",
    "# MADHUKAR: records 1 - 5000\n",
    "# SHOBHA: records 5000 - 10000\n",
    "# RADHIKA: records 10000 - 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "naked-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features present in nhd_stats for corresponding comid\n",
    "# read in fl_comid_list, pull out matching variable values in nhd_stats\n",
    "\n",
    "df_merged = df_merged_full\n",
    "\n",
    "def extract_feature(comid, feature):\n",
    "    \"\"\"\n",
    "    Extract features present in nhd_stats for corresponding comid\n",
    "    \"\"\"\n",
    "    if comid == None:\n",
    "        return np.nan # if no comid's in GEE\n",
    "    extracted_feature = nhd_stats[nhd_stats[\"comid\"] == comid][str(feature)]\n",
    "    try:\n",
    "        extracted_feature = np.array(extracted_feature).item() \n",
    "    except Exception as e:\n",
    "        return np.nan # if comid in GEE but not in nhd database\n",
    "    return extracted_feature\n",
    "\n",
    "\n",
    "def extract_sum(feature):\n",
    "    \"\"\"\n",
    "    feature engineering per excel sheet\n",
    "    \"\"\"\n",
    "    return (df_merged.apply(lambda x: np.sum(np.array([extract_feature(comid, str(feature))\n",
    "                                                                 for comid in x.fl_comid_list])\n",
    "                                                       [~np.isnan(np.array([extract_feature(comid, str(feature))\n",
    "                                                                            for comid in x.fl_comid_list]))]), \n",
    "                                                axis=1))\n",
    "def extract_count(feature):\n",
    "    \"\"\"\n",
    "    feature engineering per excel sheet\n",
    "    \"\"\"\n",
    "    return (df_merged.apply(lambda x: len(np.array([extract_feature(comid, str(feature))\n",
    "                                                                 for comid in x.fl_comid_list])\n",
    "                                                       [~np.isnan(np.array([extract_feature(comid, str(feature))\n",
    "                                                                            for comid in x.fl_comid_list]))]), \n",
    "                                                  axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "departmental-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flowline variables\n",
    "\n",
    "# areasqkm\n",
    "df_merged[\"fl_areasqkm_sum\"] = extract_sum(\"areasqkm\")\n",
    "df_merged[\"fl_areasqkm_count\"] = extract_count(\"areasqkm\")\n",
    "df_merged[\"fl_areasqkm_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                 (x.fl_areasqkm_sum/x.fl_areasqkm_count) \n",
    "                                                 if x.fl_areasqkm_count != 0 \n",
    "#                                                  else np.nan, axis=1)) # here you want to return 0\n",
    "                                                 else 0, axis=1))\n",
    "# gnis_name_ind\n",
    "df_merged[\"fl_gnis_name_ind_sum\"] = extract_sum(\"gnis_name_ind\")\n",
    "df_merged[\"fl_gnis_name_ind_count\"] = extract_count(\"gnis_name_ind\")\n",
    "df_merged[\"fl_gnis_name_ind_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                 (x.fl_gnis_name_ind_sum/x.fl_gnis_name_ind_count) \n",
    "                                                 if x.fl_gnis_name_ind_count != 0 \n",
    "#                                                  else np.nan, axis=1))\n",
    "                                                 else 0, axis=1))\n",
    "\n",
    "# totdasqkm\n",
    "df_merged[\"fl_totdasqkm_sum\"] = extract_sum(\"totdasqkm\")\n",
    "df_merged[\"fl_totdasqkm_count\"] = extract_count(\"totdasqkm\")\n",
    "df_merged[\"fl_totdasqkm_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                 (x.fl_totdasqkm_sum/x.fl_totdasqkm_count) \n",
    "                                                 if x.fl_totdasqkm_count != 0 \n",
    "#                                                  else np.nan, axis=1))\n",
    "                                                 else 0, axis=1))\n",
    "\n",
    "# flow_type\n",
    "df_merged[\"fl_flow_type_sum\"] = extract_sum(\"flow_type\")\n",
    "df_merged[\"fl_flow_type_count\"] = extract_count(\"flow_type\")\n",
    "df_merged[\"fl_flow_type_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                 (x.fl_flow_type_sum/x.fl_flow_type_count) \n",
    "                                                 if x.fl_flow_type_count != 0 \n",
    "#                                                  else np.nan, axis=1))\n",
    "                                                 else 0, axis=1))\n",
    "\n",
    "                                                  \n",
    "# streamorde\n",
    "df_merged[\"fl_streamorde_sum\"] = extract_sum(\"streamorde\")\n",
    "df_merged[\"fl_streamorde_count\"] = extract_count(\"streamorde\")\n",
    "df_merged[\"fl_streamorde_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                 (x.fl_streamorde_sum/x.fl_streamorde_count) \n",
    "                                                 if x.fl_streamorde_count != 0 \n",
    "#                                                  else np.nan, axis=1))\n",
    "                                                 else 0, axis=1))                                                   \n",
    "\n",
    "# intephem\n",
    "df_merged[\"fl_intephem_sum\"] = extract_sum(\"intephem\")\n",
    "df_merged[\"fl_intephem_count\"] = extract_count(\"intephem\")\n",
    "df_merged[\"fl_intephem_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                 (x.fl_intephem_sum/x.fl_intephem_count) \n",
    "                                                 if x.fl_intephem_count != 0 \n",
    "#                                                  else np.nan, axis=1))\n",
    "                                                 else 0, axis=1))                                                 \n",
    "\n",
    "# startflag\n",
    "df_merged[\"fl_startflag_sum\"] = extract_sum(\"startflag\")\n",
    "df_merged[\"fl_startflag_count\"] = extract_count(\"startflag\")\n",
    "df_merged[\"fl_startflag_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                 (x.fl_startflag_sum/x.fl_startflag_count) \n",
    "                                                 if x.fl_startflag_count != 0 \n",
    "#                                                  else np.nan, axis=1))\n",
    "                                                 else 0, axis=1))                                                  \n",
    "\n",
    "# divergence\n",
    "df_merged[\"fl_divergence_sum\"] = extract_sum(\"divergence\")\n",
    "df_merged[\"fl_divergence_count\"] = extract_count(\"divergence\")\n",
    "df_merged[\"fl_divergence_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                 (x.fl_divergence_sum/x.fl_divergence_count) \n",
    "                                                 if x.fl_divergence_count != 0 \n",
    "#                                                  else np.nan, axis=1))\n",
    "                                                 else 0, axis=1))                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-malta",
   "metadata": {},
   "source": [
    "# In a similar fasion, you can feature engineer the waterbodies (I will get that later today/tomorrow and push the updated dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "historical-mortality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>rha_determination</th>\n",
       "      <th>cwa_determination</th>\n",
       "      <th>rha1</th>\n",
       "      <th>rha2</th>\n",
       "      <th>cwa1</th>\n",
       "      <th>cwa2</th>\n",
       "      <th>...</th>\n",
       "      <th>fl_streamorde_mean</th>\n",
       "      <th>fl_intephem_sum</th>\n",
       "      <th>fl_intephem_count</th>\n",
       "      <th>fl_intephem_mean</th>\n",
       "      <th>fl_startflag_sum</th>\n",
       "      <th>fl_startflag_count</th>\n",
       "      <th>fl_startflag_mean</th>\n",
       "      <th>fl_divergence_sum</th>\n",
       "      <th>fl_divergence_count</th>\n",
       "      <th>fl_divergence_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7309.000000</td>\n",
       "      <td>7309.000000</td>\n",
       "      <td>-90.491852</td>\n",
       "      <td>37.209405</td>\n",
       "      <td>0.104932</td>\n",
       "      <td>0.369588</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>0.062727</td>\n",
       "      <td>0.093235</td>\n",
       "      <td>0.063889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329004</td>\n",
       "      <td>0.059101</td>\n",
       "      <td>0.232779</td>\n",
       "      <td>0.054015</td>\n",
       "      <td>0.066968</td>\n",
       "      <td>0.206033</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>0.206033</td>\n",
       "      <td>0.006733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4220.286128</td>\n",
       "      <td>4220.286128</td>\n",
       "      <td>15.418083</td>\n",
       "      <td>6.766997</td>\n",
       "      <td>0.306476</td>\n",
       "      <td>0.482710</td>\n",
       "      <td>0.256725</td>\n",
       "      <td>0.242479</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0.244564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994656</td>\n",
       "      <td>0.250179</td>\n",
       "      <td>0.551299</td>\n",
       "      <td>0.223712</td>\n",
       "      <td>0.252696</td>\n",
       "      <td>0.504558</td>\n",
       "      <td>0.239481</td>\n",
       "      <td>0.163613</td>\n",
       "      <td>0.504558</td>\n",
       "      <td>0.098222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-174.197880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3654.500000</td>\n",
       "      <td>3654.500000</td>\n",
       "      <td>-93.638850</td>\n",
       "      <td>32.815575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7309.000000</td>\n",
       "      <td>7309.000000</td>\n",
       "      <td>-88.186500</td>\n",
       "      <td>35.478300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10963.500000</td>\n",
       "      <td>10963.500000</td>\n",
       "      <td>-80.226955</td>\n",
       "      <td>41.403750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14618.000000</td>\n",
       "      <td>14618.000000</td>\n",
       "      <td>144.828420</td>\n",
       "      <td>70.483790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1     longitude      latitude  \\\n",
       "count  14619.000000  14619.000000  14619.000000  14619.000000   \n",
       "mean    7309.000000   7309.000000    -90.491852     37.209405   \n",
       "std     4220.286128   4220.286128     15.418083      6.766997   \n",
       "min        0.000000      0.000000   -174.197880      0.000000   \n",
       "25%     3654.500000   3654.500000    -93.638850     32.815575   \n",
       "50%     7309.000000   7309.000000    -88.186500     35.478300   \n",
       "75%    10963.500000  10963.500000    -80.226955     41.403750   \n",
       "max    14618.000000  14618.000000    144.828420     70.483790   \n",
       "\n",
       "       rha_determination  cwa_determination          rha1          rha2  \\\n",
       "count       14619.000000       14619.000000  14619.000000  14619.000000   \n",
       "mean            0.104932           0.369588      0.070935      0.062727   \n",
       "std             0.306476           0.482710      0.256725      0.242479   \n",
       "min             0.000000           0.000000      0.000000      0.000000   \n",
       "25%             0.000000           0.000000      0.000000      0.000000   \n",
       "50%             0.000000           0.000000      0.000000      0.000000   \n",
       "75%             0.000000           1.000000      0.000000      0.000000   \n",
       "max             1.000000           1.000000      1.000000      1.000000   \n",
       "\n",
       "               cwa1          cwa2  ...  fl_streamorde_mean  fl_intephem_sum  \\\n",
       "count  14619.000000  14619.000000  ...        14619.000000     14619.000000   \n",
       "mean       0.093235      0.063889  ...            0.329004         0.059101   \n",
       "std        0.290771      0.244564  ...            0.994656         0.250179   \n",
       "min        0.000000      0.000000  ...            0.000000         0.000000   \n",
       "25%        0.000000      0.000000  ...            0.000000         0.000000   \n",
       "50%        0.000000      0.000000  ...            0.000000         0.000000   \n",
       "75%        0.000000      0.000000  ...            0.000000         0.000000   \n",
       "max        1.000000      1.000000  ...           10.000000         3.000000   \n",
       "\n",
       "       fl_intephem_count  fl_intephem_mean  fl_startflag_sum  \\\n",
       "count       14619.000000      14619.000000      14619.000000   \n",
       "mean            0.232779          0.054015          0.066968   \n",
       "std             0.551299          0.223712          0.252696   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             0.000000          0.000000          0.000000   \n",
       "75%             0.000000          0.000000          0.000000   \n",
       "max             7.000000          1.000000          2.000000   \n",
       "\n",
       "       fl_startflag_count  fl_startflag_mean  fl_divergence_sum  \\\n",
       "count        14619.000000       14619.000000       14619.000000   \n",
       "mean             0.206033           0.062722           0.010739   \n",
       "std              0.504558           0.239481           0.163613   \n",
       "min              0.000000           0.000000           0.000000   \n",
       "25%              0.000000           0.000000           0.000000   \n",
       "50%              0.000000           0.000000           0.000000   \n",
       "75%              0.000000           0.000000           0.000000   \n",
       "max              6.000000           1.000000           6.000000   \n",
       "\n",
       "       fl_divergence_count  fl_divergence_mean  \n",
       "count         14619.000000        14619.000000  \n",
       "mean              0.206033            0.006733  \n",
       "std               0.504558            0.098222  \n",
       "min               0.000000            0.000000  \n",
       "25%               0.000000            0.000000  \n",
       "50%               0.000000            0.000000  \n",
       "75%               0.000000            0.000000  \n",
       "max               6.000000            2.000000  \n",
       "\n",
       "[8 rows x 47 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "medieval-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the variables that needs to be made accessible to manipulation via csv files\n",
    "# wb_ftype_str_list\n",
    "# wb_area_list\n",
    "# fl_ftype_str_list\n",
    "# fl_length_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adaptive-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged\n",
    "\n",
    "# wb for waterbodies\n",
    "# extract the individual lists\n",
    "df[\"wb_comid_str\"] = df.apply(lambda x: \"+\".join([str(comid) for comid in x.nhd_vars_wb[0]]), axis=1)\n",
    "df[\"wb_ftype_str\"] = df.apply(lambda x: \"+\".join([str(ftype) for ftype in x.nhd_vars_wb[1] if ftype != None]), axis=1)\n",
    "df[\"wb_gnis_id_str\"] = df.apply(lambda x: \"+\".join([str(gnis) for gnis in x.nhd_vars_wb[2]]), axis=1)\n",
    "\n",
    "# # sum and mean\n",
    "df[\"wb_area_sum\"] = df.apply(lambda x: np.sum(np.array([area for area in x.nhd_vars_wb[3] if area != None])), axis=1)\n",
    "df[\"wb_area_count\"] = df.apply(lambda x: len([area for area in x.nhd_vars_wb[3] if area != None]), axis=1)\n",
    "# df[\"wb_area_mean\"] = df.apply(lambda x: (x.wb_area_sum / x.wb_area_count) if x.wb_area_count != 0 else np.nan, axis=1)\n",
    "df[\"wb_area_mean\"] = df.apply(lambda x: (x.wb_area_sum / x.wb_area_count) if x.wb_area_count != 0 else 0, axis=1)\n",
    "\n",
    "df[\"wb_gnis_name_ind_sum\"] = df.apply(lambda x: np.sum(np.array([int(gnis) for gnis in x.nhd_vars_wb[2] if gnis not in [\"\", None]])), axis=1)\n",
    "df[\"wb_gnis_name_ind_count\"] = df.apply(lambda x: len([gnis for gnis in x.nhd_vars_wb[2] if gnis not in [\"\", None]]), axis=1)\n",
    "# df[\"wb_gnis_name_ind_mean\"] = df.apply(lambda x: (x.wb_gnis_name_ind_sum / x.wb_gnis_name_ind_count) if x.wb_gnis_name_ind_count != 0 else np.nan, axis=1)\n",
    "df[\"wb_gnis_name_ind_mean\"] = df.apply(lambda x: (x.wb_gnis_name_ind_sum / x.wb_gnis_name_ind_count) if x.wb_gnis_name_ind_count != 0 else 0, axis=1)\n",
    "\n",
    "\n",
    "# # fl for flowlines\n",
    "# # extract the individual lists\n",
    "df[\"fl_comid_str\"] = df.apply(lambda x: \"+\".join([str(comid) for comid in x.nhd_vars_fl[0]]), axis=1)\n",
    "df[\"fl_ftype_str\"] = df.apply(lambda x: \"+\".join([str(ftype) for ftype in x.nhd_vars_fl[1]]), axis=1)\n",
    "df[\"fl_gnis_id_str\"] = df.apply(lambda x: \"+\".join(x.nhd_vars_fl[2]), axis=1)\n",
    "\n",
    "# # sum and mean\n",
    "df[\"fl_length_sum\"] = df.apply(lambda x: np.sum(np.array([length for length in x.nhd_vars_wb[4] if length != None])), axis=1)\n",
    "df[\"fl_length_count\"] = df.apply(lambda x: len([length for length in x.nhd_vars_wb[4] if length != None]), axis=1)\n",
    "# df[\"fl_length_mean\"] = df.apply(lambda x: (x.fl_length_sum / x.fl_length_count) if x.fl_length_count != 0 else np.nan, axis=1)\n",
    "df[\"fl_length_mean\"] = df.apply(lambda x: (x.fl_length_sum / x.fl_length_count) if x.fl_length_count != 0 else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "formed-austin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'jurisdiction_type', 'da_number',\n",
       "       'district', 'project_name', 'longitude', 'latitude',\n",
       "       'date_issued_or_denied', 'rha_determination', 'cwa_determination',\n",
       "       'rha1', 'rha2', 'cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6', 'cwa7',\n",
       "       'cwa8', 'cwa9', 'potential_wetland', 'index', 'Index', 'mukey',\n",
       "       'hydclprs', 'aws025wta', 'drclassdcd', 'nhd_vars_wb', 'nhd_vars_fl',\n",
       "       'wb_comid_list', 'wb_ftype_str_list', 'wb_gnis_id_list', 'wb_area_list',\n",
       "       'fl_comid_list', 'fl_ftype_str_list', 'fl_gnis_id_list',\n",
       "       'fl_length_list', 'fl_areasqkm_sum', 'fl_areasqkm_count',\n",
       "       'fl_areasqkm_mean', 'fl_gnis_name_ind_sum', 'fl_gnis_name_ind_count',\n",
       "       'fl_gnis_name_ind_mean', 'fl_totdasqkm_sum', 'fl_totdasqkm_count',\n",
       "       'fl_totdasqkm_mean', 'fl_flow_type_sum', 'fl_flow_type_count',\n",
       "       'fl_flow_type_mean', 'fl_streamorde_sum', 'fl_streamorde_count',\n",
       "       'fl_streamorde_mean', 'fl_intephem_sum', 'fl_intephem_count',\n",
       "       'fl_intephem_mean', 'fl_startflag_sum', 'fl_startflag_count',\n",
       "       'fl_startflag_mean', 'fl_divergence_sum', 'fl_divergence_count',\n",
       "       'fl_divergence_mean', 'wb_comid_str', 'wb_ftype_str', 'wb_gnis_id_str',\n",
       "       'wb_area_sum', 'wb_area_count', 'wb_area_mean', 'wb_gnis_name_ind_sum',\n",
       "       'wb_gnis_name_ind_count', 'wb_gnis_name_ind_mean', 'fl_comid_str',\n",
       "       'fl_ftype_str', 'fl_gnis_id_str', 'fl_length_sum', 'fl_length_count',\n",
       "       'fl_length_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "parliamentary-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# use protocol 3 for backwards compatibility with Python 3.6 on AWS\n",
    "pickle.dump(df, open(\"2021.03.09_nhd_variables_extracted_from_200mX200m_pkl3.pkl\",\"wb\"), protocol=3)\n",
    "df.to_csv(\"2021.03.09_nhd_variables_extracted_from_200mX200m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "necessary-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.to_pickle(\"combined_regular_with_ssurgo_nhd_2.5kmX2.5km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ethical-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"combined_regular_with_ssurgo_nhd_2.5kmX2.5km.csv\")\n",
    "# df.to_pickle(\"combined_regular_with_ssurgo_nhd_2.5kmX2.5km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "loaded-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"combined_regular_with_ssurgo_nhd_200mX200m.csv\")\n",
    "# df.to_pickle(\"combined_regular_with_ssurgo_nhd_200mX200m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "atmospheric-median",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>rha_determination</th>\n",
       "      <th>cwa_determination</th>\n",
       "      <th>rha1</th>\n",
       "      <th>rha2</th>\n",
       "      <th>cwa1</th>\n",
       "      <th>cwa2</th>\n",
       "      <th>...</th>\n",
       "      <th>fl_divergence_mean</th>\n",
       "      <th>wb_area_sum</th>\n",
       "      <th>wb_area_count</th>\n",
       "      <th>wb_area_mean</th>\n",
       "      <th>wb_gnis_name_ind_sum</th>\n",
       "      <th>wb_gnis_name_ind_count</th>\n",
       "      <th>wb_gnis_name_ind_mean</th>\n",
       "      <th>fl_length_sum</th>\n",
       "      <th>fl_length_count</th>\n",
       "      <th>fl_length_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>1.461900e+04</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>1.461900e+04</td>\n",
       "      <td>13325.0</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>13325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7309.000000</td>\n",
       "      <td>7309.000000</td>\n",
       "      <td>-90.491852</td>\n",
       "      <td>37.209405</td>\n",
       "      <td>0.104932</td>\n",
       "      <td>0.369588</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>0.062727</td>\n",
       "      <td>0.093235</td>\n",
       "      <td>0.063889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>139.840426</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>139.377298</td>\n",
       "      <td>3.175971e+04</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>3.146162e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4220.286128</td>\n",
       "      <td>4220.286128</td>\n",
       "      <td>15.418083</td>\n",
       "      <td>6.766997</td>\n",
       "      <td>0.306476</td>\n",
       "      <td>0.482710</td>\n",
       "      <td>0.256725</td>\n",
       "      <td>0.242479</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0.244564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098222</td>\n",
       "      <td>2420.182459</td>\n",
       "      <td>0.268155</td>\n",
       "      <td>2420.056593</td>\n",
       "      <td>1.994140e+05</td>\n",
       "      <td>0.172667</td>\n",
       "      <td>1.969949e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317055</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-174.197880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3654.500000</td>\n",
       "      <td>3654.500000</td>\n",
       "      <td>-93.638850</td>\n",
       "      <td>32.815575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7309.000000</td>\n",
       "      <td>7309.000000</td>\n",
       "      <td>-88.186500</td>\n",
       "      <td>35.478300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10963.500000</td>\n",
       "      <td>10963.500000</td>\n",
       "      <td>-80.226955</td>\n",
       "      <td>41.403750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14618.000000</td>\n",
       "      <td>14618.000000</td>\n",
       "      <td>144.828420</td>\n",
       "      <td>70.483790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>57516.647000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>57516.647000</td>\n",
       "      <td>3.371068e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.863850e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1     longitude      latitude  \\\n",
       "count  14619.000000  14619.000000  14619.000000  14619.000000   \n",
       "mean    7309.000000   7309.000000    -90.491852     37.209405   \n",
       "std     4220.286128   4220.286128     15.418083      6.766997   \n",
       "min        0.000000      0.000000   -174.197880      0.000000   \n",
       "25%     3654.500000   3654.500000    -93.638850     32.815575   \n",
       "50%     7309.000000   7309.000000    -88.186500     35.478300   \n",
       "75%    10963.500000  10963.500000    -80.226955     41.403750   \n",
       "max    14618.000000  14618.000000    144.828420     70.483790   \n",
       "\n",
       "       rha_determination  cwa_determination          rha1          rha2  \\\n",
       "count       14619.000000       14619.000000  14619.000000  14619.000000   \n",
       "mean            0.104932           0.369588      0.070935      0.062727   \n",
       "std             0.306476           0.482710      0.256725      0.242479   \n",
       "min             0.000000           0.000000      0.000000      0.000000   \n",
       "25%             0.000000           0.000000      0.000000      0.000000   \n",
       "50%             0.000000           0.000000      0.000000      0.000000   \n",
       "75%             0.000000           1.000000      0.000000      0.000000   \n",
       "max             1.000000           1.000000      1.000000      1.000000   \n",
       "\n",
       "               cwa1          cwa2  ...  fl_divergence_mean   wb_area_sum  \\\n",
       "count  14619.000000  14619.000000  ...        14619.000000  14619.000000   \n",
       "mean       0.093235      0.063889  ...            0.006733    139.840426   \n",
       "std        0.290771      0.244564  ...            0.098222   2420.182459   \n",
       "min        0.000000      0.000000  ...            0.000000      0.000000   \n",
       "25%        0.000000      0.000000  ...            0.000000      0.000000   \n",
       "50%        0.000000      0.000000  ...            0.000000      0.000000   \n",
       "75%        0.000000      0.000000  ...            0.000000      0.000000   \n",
       "max        1.000000      1.000000  ...            2.000000  57516.647000   \n",
       "\n",
       "       wb_area_count  wb_area_mean  wb_gnis_name_ind_sum  \\\n",
       "count   14619.000000  14619.000000          1.461900e+04   \n",
       "mean        0.065052    139.377298          3.175971e+04   \n",
       "std         0.268155   2420.056593          1.994140e+05   \n",
       "min         0.000000      0.000000          0.000000e+00   \n",
       "25%         0.000000      0.000000          0.000000e+00   \n",
       "50%         0.000000      0.000000          0.000000e+00   \n",
       "75%         0.000000      0.000000          0.000000e+00   \n",
       "max         3.000000  57516.647000          3.371068e+06   \n",
       "\n",
       "       wb_gnis_name_ind_count  wb_gnis_name_ind_mean  fl_length_sum  \\\n",
       "count            14619.000000           1.461900e+04        13325.0   \n",
       "mean                 0.030029           3.146162e+04            0.0   \n",
       "std                  0.172667           1.969949e+05            0.0   \n",
       "min                  0.000000           0.000000e+00            0.0   \n",
       "25%                  0.000000           0.000000e+00            0.0   \n",
       "50%                  0.000000           0.000000e+00            0.0   \n",
       "75%                  0.000000           0.000000e+00            0.0   \n",
       "max                  2.000000           1.863850e+06            0.0   \n",
       "\n",
       "       fl_length_count  fl_length_mean  \n",
       "count     14619.000000         13325.0  \n",
       "mean          0.095219             0.0  \n",
       "std           0.317055             0.0  \n",
       "min           0.000000             0.0  \n",
       "25%           0.000000             0.0  \n",
       "50%           0.000000             0.0  \n",
       "75%           0.000000             0.0  \n",
       "max           3.000000             0.0  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(\"combined_regular_with_ssurgo_nhd_2.5kmX2.5km_pkl3.pkl\", \"rb\") as f:\n",
    "#     df_readfrompkl = pickle.load(f)\n",
    "\n",
    "df = pd.read_pickle(\"2021.03.09_nhd_variables_extracted_from_200mX200m_pkl3.pkl\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "reported-mattress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'jurisdiction_type', 'da_number',\n",
       "       'district', 'project_name', 'longitude', 'latitude',\n",
       "       'date_issued_or_denied', 'rha_determination', 'cwa_determination',\n",
       "       'rha1', 'rha2', 'cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6', 'cwa7',\n",
       "       'cwa8', 'cwa9', 'potential_wetland', 'index', 'Index', 'mukey',\n",
       "       'hydclprs', 'aws025wta', 'drclassdcd', 'nhd_vars_wb', 'nhd_vars_fl',\n",
       "       'wb_comid_list', 'wb_ftype_str_list', 'wb_gnis_id_list', 'wb_area_list',\n",
       "       'fl_comid_list', 'fl_ftype_str_list', 'fl_gnis_id_list',\n",
       "       'fl_length_list', 'fl_areasqkm_sum', 'fl_areasqkm_count',\n",
       "       'fl_areasqkm_mean', 'fl_gnis_name_ind_sum', 'fl_gnis_name_ind_count',\n",
       "       'fl_gnis_name_ind_mean', 'fl_totdasqkm_sum', 'fl_totdasqkm_count',\n",
       "       'fl_totdasqkm_mean', 'fl_flow_type_sum', 'fl_flow_type_count',\n",
       "       'fl_flow_type_mean', 'fl_streamorde_sum', 'fl_streamorde_count',\n",
       "       'fl_streamorde_mean', 'fl_intephem_sum', 'fl_intephem_count',\n",
       "       'fl_intephem_mean', 'fl_startflag_sum', 'fl_startflag_count',\n",
       "       'fl_startflag_mean', 'fl_divergence_sum', 'fl_divergence_count',\n",
       "       'fl_divergence_mean', 'wb_comid_str', 'wb_ftype_str', 'wb_gnis_id_str',\n",
       "       'wb_area_sum', 'wb_area_count', 'wb_area_mean', 'wb_gnis_name_ind_sum',\n",
       "       'wb_gnis_name_ind_count', 'wb_gnis_name_ind_mean', 'fl_comid_str',\n",
       "       'fl_ftype_str', 'fl_gnis_id_str', 'fl_length_sum', 'fl_length_count',\n",
       "       'fl_length_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "academic-abraham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_areasqkm_sum</th>\n",
       "      <th>fl_areasqkm_count</th>\n",
       "      <th>fl_areasqkm_mean</th>\n",
       "      <th>fl_gnis_name_ind_sum</th>\n",
       "      <th>fl_gnis_name_ind_count</th>\n",
       "      <th>fl_gnis_name_ind_mean</th>\n",
       "      <th>fl_totdasqkm_sum</th>\n",
       "      <th>fl_totdasqkm_count</th>\n",
       "      <th>fl_totdasqkm_mean</th>\n",
       "      <th>fl_flow_type_sum</th>\n",
       "      <th>fl_flow_type_count</th>\n",
       "      <th>fl_flow_type_mean</th>\n",
       "      <th>fl_streamorde_sum</th>\n",
       "      <th>fl_streamorde_count</th>\n",
       "      <th>fl_streamorde_mean</th>\n",
       "      <th>fl_intephem_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14614</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14615</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14616</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14617</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14618</th>\n",
       "      <td>3.6135</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6135</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14619 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fl_areasqkm_sum  fl_areasqkm_count  fl_areasqkm_mean  \\\n",
       "0               0.0000                  0            0.0000   \n",
       "1               0.0000                  0            0.0000   \n",
       "2               0.0000                  0            0.0000   \n",
       "3               0.0000                  0            0.0000   \n",
       "4               0.0000                  0            0.0000   \n",
       "...                ...                ...               ...   \n",
       "14614           0.0000                  0            0.0000   \n",
       "14615           0.0000                  0            0.0000   \n",
       "14616           0.0000                  0            0.0000   \n",
       "14617           0.0000                  0            0.0000   \n",
       "14618           3.6135                  1            3.6135   \n",
       "\n",
       "       fl_gnis_name_ind_sum  fl_gnis_name_ind_count  fl_gnis_name_ind_mean  \\\n",
       "0                       0.0                       0                    0.0   \n",
       "1                       0.0                       0                    0.0   \n",
       "2                       0.0                       0                    0.0   \n",
       "3                       0.0                       0                    0.0   \n",
       "4                       0.0                       0                    0.0   \n",
       "...                     ...                     ...                    ...   \n",
       "14614                   0.0                       1                    0.0   \n",
       "14615                   0.0                       0                    0.0   \n",
       "14616                   0.0                       0                    0.0   \n",
       "14617                   0.0                       0                    0.0   \n",
       "14618                   0.0                       1                    0.0   \n",
       "\n",
       "       fl_totdasqkm_sum  fl_totdasqkm_count  fl_totdasqkm_mean  \\\n",
       "0                0.0000                   0             0.0000   \n",
       "1                0.0000                   0             0.0000   \n",
       "2                0.0000                   0             0.0000   \n",
       "3                0.0000                   0             0.0000   \n",
       "4                0.0000                   0             0.0000   \n",
       "...                 ...                 ...                ...   \n",
       "14614            0.0000                   0             0.0000   \n",
       "14615            0.0000                   0             0.0000   \n",
       "14616            0.0000                   0             0.0000   \n",
       "14617            0.0000                   0             0.0000   \n",
       "14618            3.6135                   1             3.6135   \n",
       "\n",
       "       fl_flow_type_sum  fl_flow_type_count  fl_flow_type_mean  \\\n",
       "0                   0.0                   0                0.0   \n",
       "1                   0.0                   0                0.0   \n",
       "2                   0.0                   0                0.0   \n",
       "3                   0.0                   0                0.0   \n",
       "4                   0.0                   0                0.0   \n",
       "...                 ...                 ...                ...   \n",
       "14614               0.0                   1                0.0   \n",
       "14615               0.0                   0                0.0   \n",
       "14616               0.0                   0                0.0   \n",
       "14617               0.0                   0                0.0   \n",
       "14618               1.0                   1                1.0   \n",
       "\n",
       "       fl_streamorde_sum  fl_streamorde_count  fl_streamorde_mean  \\\n",
       "0                    0.0                    0                 0.0   \n",
       "1                    0.0                    0                 0.0   \n",
       "2                    0.0                    0                 0.0   \n",
       "3                    0.0                    0                 0.0   \n",
       "4                    0.0                    0                 0.0   \n",
       "...                  ...                  ...                 ...   \n",
       "14614                0.0                    0                 0.0   \n",
       "14615                0.0                    0                 0.0   \n",
       "14616                0.0                    0                 0.0   \n",
       "14617                0.0                    0                 0.0   \n",
       "14618                1.0                    1                 1.0   \n",
       "\n",
       "       fl_intephem_sum  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "14614              1.0  \n",
       "14615              0.0  \n",
       "14616              0.0  \n",
       "14617              0.0  \n",
       "14618              1.0  \n",
       "\n",
       "[14619 rows x 16 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alist = ['fl_areasqkm_sum', 'fl_areasqkm_count',\n",
    "       'fl_areasqkm_mean', 'fl_gnis_name_ind_sum', 'fl_gnis_name_ind_count',\n",
    "       'fl_gnis_name_ind_mean', 'fl_totdasqkm_sum', 'fl_totdasqkm_count',\n",
    "       'fl_totdasqkm_mean', 'fl_flow_type_sum', 'fl_flow_type_count',\n",
    "       'fl_flow_type_mean', 'fl_streamorde_sum', 'fl_streamorde_count',\n",
    "       'fl_streamorde_mean', 'fl_intephem_sum']\n",
    "df[alist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "affecting-silver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_intephem_count</th>\n",
       "      <th>fl_intephem_mean</th>\n",
       "      <th>fl_startflag_sum</th>\n",
       "      <th>fl_startflag_count</th>\n",
       "      <th>fl_startflag_mean</th>\n",
       "      <th>fl_divergence_sum</th>\n",
       "      <th>fl_divergence_count</th>\n",
       "      <th>fl_divergence_mean</th>\n",
       "      <th>wb_area_sum</th>\n",
       "      <th>wb_area_count</th>\n",
       "      <th>wb_area_mean</th>\n",
       "      <th>wb_gnis_name_ind_sum</th>\n",
       "      <th>wb_gnis_name_ind_count</th>\n",
       "      <th>wb_gnis_name_ind_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>1.461900e+04</td>\n",
       "      <td>14619.000000</td>\n",
       "      <td>1.461900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.232779</td>\n",
       "      <td>0.054015</td>\n",
       "      <td>0.066968</td>\n",
       "      <td>0.206033</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>0.206033</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>139.840426</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>139.377298</td>\n",
       "      <td>3.175971e+04</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>3.146162e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.551299</td>\n",
       "      <td>0.223712</td>\n",
       "      <td>0.252696</td>\n",
       "      <td>0.504558</td>\n",
       "      <td>0.239481</td>\n",
       "      <td>0.163613</td>\n",
       "      <td>0.504558</td>\n",
       "      <td>0.098222</td>\n",
       "      <td>2420.182459</td>\n",
       "      <td>0.268155</td>\n",
       "      <td>2420.056593</td>\n",
       "      <td>1.994140e+05</td>\n",
       "      <td>0.172667</td>\n",
       "      <td>1.969949e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>57516.647000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>57516.647000</td>\n",
       "      <td>3.371068e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.863850e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fl_intephem_count  fl_intephem_mean  fl_startflag_sum  \\\n",
       "count       14619.000000      14619.000000      14619.000000   \n",
       "mean            0.232779          0.054015          0.066968   \n",
       "std             0.551299          0.223712          0.252696   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             0.000000          0.000000          0.000000   \n",
       "75%             0.000000          0.000000          0.000000   \n",
       "max             7.000000          1.000000          2.000000   \n",
       "\n",
       "       fl_startflag_count  fl_startflag_mean  fl_divergence_sum  \\\n",
       "count        14619.000000       14619.000000       14619.000000   \n",
       "mean             0.206033           0.062722           0.010739   \n",
       "std              0.504558           0.239481           0.163613   \n",
       "min              0.000000           0.000000           0.000000   \n",
       "25%              0.000000           0.000000           0.000000   \n",
       "50%              0.000000           0.000000           0.000000   \n",
       "75%              0.000000           0.000000           0.000000   \n",
       "max              6.000000           1.000000           6.000000   \n",
       "\n",
       "       fl_divergence_count  fl_divergence_mean   wb_area_sum  wb_area_count  \\\n",
       "count         14619.000000        14619.000000  14619.000000   14619.000000   \n",
       "mean              0.206033            0.006733    139.840426       0.065052   \n",
       "std               0.504558            0.098222   2420.182459       0.268155   \n",
       "min               0.000000            0.000000      0.000000       0.000000   \n",
       "25%               0.000000            0.000000      0.000000       0.000000   \n",
       "50%               0.000000            0.000000      0.000000       0.000000   \n",
       "75%               0.000000            0.000000      0.000000       0.000000   \n",
       "max               6.000000            2.000000  57516.647000       3.000000   \n",
       "\n",
       "       wb_area_mean  wb_gnis_name_ind_sum  wb_gnis_name_ind_count  \\\n",
       "count  14619.000000          1.461900e+04            14619.000000   \n",
       "mean     139.377298          3.175971e+04                0.030029   \n",
       "std     2420.056593          1.994140e+05                0.172667   \n",
       "min        0.000000          0.000000e+00                0.000000   \n",
       "25%        0.000000          0.000000e+00                0.000000   \n",
       "50%        0.000000          0.000000e+00                0.000000   \n",
       "75%        0.000000          0.000000e+00                0.000000   \n",
       "max    57516.647000          3.371068e+06                2.000000   \n",
       "\n",
       "       wb_gnis_name_ind_mean  \n",
       "count           1.461900e+04  \n",
       "mean            3.146162e+04  \n",
       "std             1.969949e+05  \n",
       "min             0.000000e+00  \n",
       "25%             0.000000e+00  \n",
       "50%             0.000000e+00  \n",
       "75%             0.000000e+00  \n",
       "max             1.863850e+06  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blist = ['fl_intephem_count',\n",
    "       'fl_intephem_mean', 'fl_startflag_sum', 'fl_startflag_count',\n",
    "       'fl_startflag_mean', 'fl_divergence_sum', 'fl_divergence_count',\n",
    "       'fl_divergence_mean', 'wb_comid_str', 'wb_ftype_str', 'wb_gnis_id_str',\n",
    "       'wb_area_sum', 'wb_area_count', 'wb_area_mean', 'wb_gnis_name_ind_sum',\n",
    "       'wb_gnis_name_ind_count', 'wb_gnis_name_ind_mean']\n",
    "df[blist].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-stephen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
