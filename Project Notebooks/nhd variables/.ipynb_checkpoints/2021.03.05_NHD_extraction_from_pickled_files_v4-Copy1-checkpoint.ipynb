{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technical-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mental-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the nhd addendum file\n",
    "nhd_stats = pd.read_csv(\"nhd_stats_AI.csv\")\n",
    "\n",
    "# read in csv file with SSURGO variables\n",
    "df_m = pd.read_csv(\"combined_regular_clean_with_ssurgo_variables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liable-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comid's from GEE are extracted into several pickled files\n",
    "# pickling is needed to be able to share easily across team members \n",
    "# join these pickled files into one full dataset\n",
    "\n",
    "df_merged_full = []\n",
    "\n",
    "for i in range(df_m.shape[0] // 500 + 1):\n",
    "    try:\n",
    "        df_temp = pd.read_pickle(('NHD_extracted_vars_2.5kmX2.5km/combined_regular_clean_with_ssurgo_nhd_variables_part' + \n",
    "                              str(500 * i + 1)))\n",
    "    except:\n",
    "        break\n",
    "    df_merged_full.append(df_temp)\n",
    "df_merged_full = pd.concat(df_merged_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adult-revelation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'jurisdiction_type', 'da_number',\n",
       "       'district', 'project_name', 'longitude', 'latitude',\n",
       "       'date_issued_or_denied', 'rha_determination', 'cwa_determination',\n",
       "       'rha1', 'rha2', 'cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6', 'cwa7',\n",
       "       'cwa8', 'cwa9', 'potential_wetland', 'index', 'Index', 'mukey',\n",
       "       'hydclprs', 'aws025wta', 'drclassdcd', 'nhd_vars_wb', 'nhd_vars_fl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-pride",
   "metadata": {},
   "source": [
    "# A word on 'nhd_vars_wb' and 'nhd_vars_fl' columns (see last two columns above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-potter",
   "metadata": {},
   "source": [
    "## nhd_vars_wb: this is a list of lists\n",
    "- for each record, the following six features from GEE are extracted as lists and stored into a list\n",
    "- [comid_list, ftype_str, gnis_id, wb_area, fl_length, fcode]\n",
    "- the column is labeled nhd_vars_wb for waterbodies\n",
    "\n",
    "In a similar fashion, there is another column for flowlines labeled nhd_vars_fl\n",
    "\n",
    "Note: fl_length is NaN's for waterbodies and wb_area ae NaN's for flowlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-plasma",
   "metadata": {},
   "source": [
    "## In the following, features are extracted from the above columns and feature engineered as discussed in meetings. Pls use your judgement to help devise any new features you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exciting-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wb for waterbodies\n",
    "# extract the individual lists\n",
    "df_merged_full[\"wb_comid_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_wb[0], axis=1)\n",
    "df_merged_full[\"wb_ftype_str_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_wb[1], axis=1)\n",
    "df_merged_full[\"wb_gnis_id_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_wb[2], axis=1)\n",
    "df_merged_full[\"wb_area_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_wb[3], axis=1)\n",
    "\n",
    "# fl for flowlines\n",
    "# extract the individual lists\n",
    "df_merged_full[\"fl_comid_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_fl[0], axis=1)\n",
    "df_merged_full[\"fl_ftype_str_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_fl[1], axis=1)\n",
    "df_merged_full[\"fl_gnis_id_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_fl[2], axis=1)\n",
    "df_merged_full[\"fl_length_list\"] = df_merged_full.apply(lambda x: x.nhd_vars_fl[4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-occupation",
   "metadata": {},
   "source": [
    "# Lets look at columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assumed-porcelain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nhd_vars_wb</th>\n",
       "      <th>nhd_vars_fl</th>\n",
       "      <th>wb_comid_list</th>\n",
       "      <th>wb_ftype_str_list</th>\n",
       "      <th>wb_gnis_id_list</th>\n",
       "      <th>wb_area_list</th>\n",
       "      <th>fl_comid_list</th>\n",
       "      <th>fl_ftype_str_list</th>\n",
       "      <th>fl_gnis_id_list</th>\n",
       "      <th>fl_length_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([120052831, 22027044], [None, None], [974076,...</td>\n",
       "      <td>([21980197, 21980245, 21980217, 21980207, 2198...</td>\n",
       "      <td>[120052831, 22027044]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[974076, ]</td>\n",
       "      <td>[171.202, 0.008]</td>\n",
       "      <td>[21980197, 21980245, 21980217, 21980207, 21980...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>[, , , , , , , , 973757, , 974058]</td>\n",
       "      <td>[0.022, 1.975, 3.135, 0.725, 2.786, 0.764, 3.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>([904140245], [None], [1075813], [12045.529], ...</td>\n",
       "      <td>([15594559, 15594563, 15594573, 15594565, 1559...</td>\n",
       "      <td>[904140245]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[1075813]</td>\n",
       "      <td>[12045.529]</td>\n",
       "      <td>[15594559, 15594563, 15594573, 15594565, 15594...</td>\n",
       "      <td>[None, None, None, None, None, None, None, None]</td>\n",
       "      <td>[, , 1066928, 1066928, 1066928, , , 1066928]</td>\n",
       "      <td>[0.602, 0.217, 1.254, 0.208, 7.518, 5.608, 12....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>([21631197, 904140246, 21631201], [None, None,...</td>\n",
       "      <td>([21632385, 21632387, 21632389, 21635915, 2163...</td>\n",
       "      <td>[21631197, 904140246, 21631201]</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>[967326, 970427, ]</td>\n",
       "      <td>[0.425, 6693.837, 0.946]</td>\n",
       "      <td>[21632385, 21632387, 21632389, 21635915, 21635...</td>\n",
       "      <td>[None, None, None, None, None, None, None, None]</td>\n",
       "      <td>[, , , , , , , ]</td>\n",
       "      <td>[2.781, 0.287, 1.895, 0.871, 10.109, 0.15, 1.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>([15586156, 15586164], [None, None], [1078482,...</td>\n",
       "      <td>([15588640, 15588636, 15587674, 15587680, 1558...</td>\n",
       "      <td>[15586156, 15586164]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[1078482, 1079552]</td>\n",
       "      <td>[0.139, 0.051]</td>\n",
       "      <td>[15588640, 15588636, 15587674, 15587680, 15587...</td>\n",
       "      <td>[None, None, None, None, None, None, None]</td>\n",
       "      <td>[, , , , 1066599, 1066599, 1066851]</td>\n",
       "      <td>[0.941, 0.658, 1.216, 0.505, 0.968, 3.143, 1.98]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>([], [], [], [], [], [])</td>\n",
       "      <td>([15560355, 15560297, 15560169, 15560311, 1556...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[15560355, 15560297, 15560169, 15560311, 15560...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>[968024, 968024, , , , , , , ]</td>\n",
       "      <td>[0.766, 4.526, 1.44, 1.941, 0.95, 0.641, 0.372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>([], [], [], [], [], [])</td>\n",
       "      <td>([15594581, 15594569, 15594591], [None, None, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[15594581, 15594569, 15594591]</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>[, 1044708, 1044708]</td>\n",
       "      <td>[1.943, 2.539, 4.12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          nhd_vars_wb  \\\n",
       "9   ([120052831, 22027044], [None, None], [974076,...   \n",
       "10  ([904140245], [None], [1075813], [12045.529], ...   \n",
       "11  ([21631197, 904140246, 21631201], [None, None,...   \n",
       "12  ([15586156, 15586164], [None, None], [1078482,...   \n",
       "13                           ([], [], [], [], [], [])   \n",
       "14                           ([], [], [], [], [], [])   \n",
       "\n",
       "                                          nhd_vars_fl  \\\n",
       "9   ([21980197, 21980245, 21980217, 21980207, 2198...   \n",
       "10  ([15594559, 15594563, 15594573, 15594565, 1559...   \n",
       "11  ([21632385, 21632387, 21632389, 21635915, 2163...   \n",
       "12  ([15588640, 15588636, 15587674, 15587680, 1558...   \n",
       "13  ([15560355, 15560297, 15560169, 15560311, 1556...   \n",
       "14  ([15594581, 15594569, 15594591], [None, None, ...   \n",
       "\n",
       "                      wb_comid_list   wb_ftype_str_list     wb_gnis_id_list  \\\n",
       "9             [120052831, 22027044]        [None, None]          [974076, ]   \n",
       "10                      [904140245]              [None]           [1075813]   \n",
       "11  [21631197, 904140246, 21631201]  [None, None, None]  [967326, 970427, ]   \n",
       "12             [15586156, 15586164]        [None, None]  [1078482, 1079552]   \n",
       "13                               []                  []                  []   \n",
       "14                               []                  []                  []   \n",
       "\n",
       "                wb_area_list  \\\n",
       "9           [171.202, 0.008]   \n",
       "10               [12045.529]   \n",
       "11  [0.425, 6693.837, 0.946]   \n",
       "12            [0.139, 0.051]   \n",
       "13                        []   \n",
       "14                        []   \n",
       "\n",
       "                                        fl_comid_list  \\\n",
       "9   [21980197, 21980245, 21980217, 21980207, 21980...   \n",
       "10  [15594559, 15594563, 15594573, 15594565, 15594...   \n",
       "11  [21632385, 21632387, 21632389, 21635915, 21635...   \n",
       "12  [15588640, 15588636, 15587674, 15587680, 15587...   \n",
       "13  [15560355, 15560297, 15560169, 15560311, 15560...   \n",
       "14                     [15594581, 15594569, 15594591]   \n",
       "\n",
       "                                    fl_ftype_str_list  \\\n",
       "9   [None, None, None, None, None, None, None, Non...   \n",
       "10   [None, None, None, None, None, None, None, None]   \n",
       "11   [None, None, None, None, None, None, None, None]   \n",
       "12         [None, None, None, None, None, None, None]   \n",
       "13  [None, None, None, None, None, None, None, Non...   \n",
       "14                                 [None, None, None]   \n",
       "\n",
       "                                 fl_gnis_id_list  \\\n",
       "9             [, , , , , , , , 973757, , 974058]   \n",
       "10  [, , 1066928, 1066928, 1066928, , , 1066928]   \n",
       "11                              [, , , , , , , ]   \n",
       "12           [, , , , 1066599, 1066599, 1066851]   \n",
       "13                [968024, 968024, , , , , , , ]   \n",
       "14                          [, 1044708, 1044708]   \n",
       "\n",
       "                                       fl_length_list  \n",
       "9   [0.022, 1.975, 3.135, 0.725, 2.786, 0.764, 3.0...  \n",
       "10  [0.602, 0.217, 1.254, 0.208, 7.518, 5.608, 12....  \n",
       "11  [2.781, 0.287, 1.895, 0.871, 10.109, 0.15, 1.1...  \n",
       "12   [0.941, 0.658, 1.216, 0.505, 0.968, 3.143, 1.98]  \n",
       "13  [0.766, 4.526, 1.44, 1.941, 0.95, 0.641, 0.372...  \n",
       "14                               [1.943, 2.539, 4.12]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_full[df_merged_full.columns[29:39]][9:15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-positive",
   "metadata": {},
   "source": [
    "## Lets look at one row in individual columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bottom-atlas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([120052831, 22027044],\n",
       " [None, None],\n",
       " ['974076', ''],\n",
       " [171.202, 0.008],\n",
       " [nan, nan],\n",
       " [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at waterbodies list\n",
    "df_merged_full.nhd_vars_wb[9]\n",
    "# you can see there are 6 items in the list [comid_list, ftype_str, gnis_id, wb_area, fl_length, fcode]\n",
    "# note that fcode is going to be null due to coding lapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expanded-performance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([21980197,\n",
       "  21980245,\n",
       "  21980217,\n",
       "  21980207,\n",
       "  21980203,\n",
       "  21980199,\n",
       "  21980195,\n",
       "  21980193,\n",
       "  21978319,\n",
       "  21978365,\n",
       "  21978323],\n",
       " [None, None, None, None, None, None, None, None, None, None, None],\n",
       " ['', '', '', '', '', '', '', '', '973757', '', '974058'],\n",
       " [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       " [0.022, 1.975, 3.135, 0.725, 2.786, 0.764, 3.016, 1.652, 3.419, 3.557, 2.136],\n",
       " [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at flowlines list\n",
    "df_merged_full.nhd_vars_fl[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "meaning-formation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[120052831, 22027044]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of comids in waterbodies\n",
    "df_merged_full.wb_comid_list[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "governing-visit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21980197,\n",
       " 21980245,\n",
       " 21980217,\n",
       " 21980207,\n",
       " 21980203,\n",
       " 21980199,\n",
       " 21980195,\n",
       " 21980193,\n",
       " 21978319,\n",
       " 21978365,\n",
       " 21978323]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of comids in flowlines\n",
    "df_merged_full.fl_comid_list[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-michael",
   "metadata": {},
   "source": [
    "### .... and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continued-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Filter out invalid comids (although not used in this notebook)\n",
    "# # \"invalid\" = present in GEE but not present in nhd_stats\n",
    "\n",
    "# df_merged[\"wb_comid_list_filtered\"] = df_merged.apply(lambda x: [comid for comid in x.nhd_vars_wb[0] if comid in np.array(nhd_stats.comid)\n",
    "#                                                                 ], axis=1)\n",
    "\n",
    "# df_merged[\"fl_comid_list_filtered\"] = df_merged.apply(lambda x: [comid for comid in x.nhd_vars_fl[0] if comid in np.array(nhd_stats.comid)\n",
    "#                                                                 ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "improved-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigned begin and end of records for each person\n",
    "# MADHUKAR: records 1 - 5000\n",
    "# SHOBHA: records 5000 - 10000\n",
    "# RADHIKA: records 10000 - 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "offensive-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged_full.copy()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "banned-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "naked-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features present in nhd_stats for corresponding comid\n",
    "# read in fl_comid_list, pull out matching variable values in nhd_stats\n",
    "\n",
    "\n",
    "\n",
    "def extract_feature(comid, feature):\n",
    "    \"\"\"\n",
    "    Extract features present in nhd_stats for corresponding comid\n",
    "    \"\"\"\n",
    "    if comid == None:\n",
    "        return np.nan # if no comid's in GEE\n",
    "    extracted_feature = nhd_stats[nhd_stats[\"comid\"] == comid][str(feature)]\n",
    "    try:\n",
    "        extracted_feature = np.array(extracted_feature).item() \n",
    "    except Exception as e:\n",
    "        return np.nan # if comid in GEE but not in nhd database\n",
    "    return extracted_feature\n",
    "\n",
    "\n",
    "def extract_sum(feature):\n",
    "    \"\"\"\n",
    "    feature engineering per excel sheet\n",
    "    \"\"\"\n",
    "    return (df_merged.apply(lambda x: np.sum(np.array([extract_feature(comid, str(feature))\n",
    "                                                                 for comid in x.fl_comid_list])\n",
    "                                                       [~np.isnan(np.array([extract_feature(comid, str(feature))\n",
    "                                                                            for comid in x.fl_comid_list]))]), \n",
    "                                                axis=1))\n",
    "def extract_count(feature):\n",
    "    \"\"\"\n",
    "    feature engineering per excel sheet\n",
    "    \"\"\"\n",
    "    return (df_merged.apply(lambda x: len(np.array([extract_feature(comid, str(feature))\n",
    "                                                                 for comid in x.fl_comid_list])\n",
    "                                                       [~np.isnan(np.array([extract_feature(comid, str(feature))\n",
    "                                                                            for comid in x.fl_comid_list]))]), \n",
    "                                                  axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lasting-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flowline variables\n",
    "\n",
    "def extract_flowline_variables(df_merged):\n",
    "\n",
    "    # areasqkm\n",
    "    df_merged[\"fl_areasqkm_sum\"] = extract_sum(\"areasqkm\")\n",
    "    df_merged[\"fl_areasqkm_count\"] = extract_count(\"areasqkm\")\n",
    "    df_merged[\"fl_areasqkm_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                     (x.fl_areasqkm_sum/x.fl_areasqkm_count) \n",
    "                                                     if x.fl_areasqkm_count != 0 \n",
    "                                                     else np.nan, axis=1))\n",
    "\n",
    "    # gnis_name_ind\n",
    "    df_merged[\"fl_gnis_name_ind_sum\"] = extract_sum(\"gnis_name_ind\")\n",
    "    df_merged[\"fl_gnis_name_ind_count\"] = extract_count(\"gnis_name_ind\")\n",
    "    df_merged[\"fl_gnis_name_ind_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                     (x.fl_areasqkm_sum/x.fl_areasqkm_count) \n",
    "                                                     if x.fl_areasqkm_count != 0 \n",
    "                                                     else np.nan, axis=1))\n",
    "\n",
    "    # totdasqkm\n",
    "    df_merged[\"fl_totdasqkm_sum\"] = extract_sum(\"totdasqkm\")\n",
    "    df_merged[\"fl_totdasqkm_count\"] = extract_count(\"totdasqkm\")\n",
    "    df_merged[\"fl_totdasqkm_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                     (x.fl_areasqkm_sum/x.fl_areasqkm_count) \n",
    "                                                     if x.fl_areasqkm_count != 0 \n",
    "                                                     else np.nan, axis=1))\n",
    "\n",
    "    # flow_type\n",
    "    df_merged[\"fl_flow_type_sum\"] = extract_sum(\"flow_type\")\n",
    "    df_merged[\"fl_flow_type_count\"] = extract_count(\"flow_type\")\n",
    "    df_merged[\"fl_flow_type_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                     (x.fl_areasqkm_sum/x.fl_areasqkm_count) \n",
    "                                                     if x.fl_areasqkm_count != 0 \n",
    "                                                     else np.nan, axis=1))\n",
    "\n",
    "    # streamorde\n",
    "    df_merged[\"fl_streamorde_sum\"] = extract_sum(\"streamorde\")\n",
    "    df_merged[\"fl_streamorde_count\"] = extract_count(\"streamorde\")\n",
    "    df_merged[\"fl_streamorde_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                     (x.fl_areasqkm_sum/x.fl_areasqkm_count) \n",
    "                                                     if x.fl_areasqkm_count != 0 \n",
    "                                                     else np.nan, axis=1))\n",
    "\n",
    "    # intephem\n",
    "    df_merged[\"fl_intephem_sum\"] = extract_sum(\"intephem\")\n",
    "    df_merged[\"fl_intephem_count\"] = extract_count(\"intephem\")\n",
    "    df_merged[\"fl_intephem_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                     (x.fl_areasqkm_sum/x.fl_areasqkm_count) \n",
    "                                                     if x.fl_areasqkm_count != 0 \n",
    "                                                     else np.nan, axis=1))\n",
    "\n",
    "    # startflag\n",
    "    df_merged[\"fl_startflag_sum\"] = extract_sum(\"startflag\")\n",
    "    df_merged[\"fl_startflag_count\"] = extract_count(\"startflag\")\n",
    "    df_merged[\"fl_startflag_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                     (x.fl_areasqkm_sum/x.fl_areasqkm_count) \n",
    "                                                     if x.fl_areasqkm_count != 0 \n",
    "                                                     else np.nan, axis=1))\n",
    "\n",
    "    # divergence\n",
    "    df_merged[\"fl_divergence_sum\"] = extract_sum(\"divergence\")\n",
    "    df_merged[\"fl_divergence_count\"] = extract_count(\"divergence\")\n",
    "    df_merged[\"fl_divergence_mean\"] = (df_merged.apply(lambda x: \n",
    "                                                     (x.fl_areasqkm_sum/x.fl_areasqkm_count) \n",
    "                                                     if x.fl_areasqkm_count != 0 \n",
    "                                                     else np.nan, axis=1))\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "theoretical-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waterbodies variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wired-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do\n",
    "\n",
    "# fcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in batches of 500\n",
    "# MADHUKAR: 0 - 5000 \n",
    "# SHOBHA: 5000 - 10000\n",
    "# RADHIKA: 10000 - 15000\n",
    "\n",
    "batch_size = 15\n",
    "MY_NAME = \"MADHUKAR\"\n",
    "START = 0 + 5000 * (MY_NAME == \"SHOBHA\") + 10000 * (MY_NAME == \"RADHIKA\")\n",
    "\n",
    "for batch in range(10):\n",
    "  print(\"batch {} of 10 started\".format(batch + 1))\n",
    "  batch_df = df_merged_full[START + batch_size * batch : START + batch_size * (batch + 1)].copy()\n",
    "  batch_df = extract_flowline_variables(batch_df)\n",
    "  part = (START + batch_size * batch) + 1\n",
    "  print(\"batch {} of 10 done\".format(batch + 1))\n",
    "  batch_df.to_pickle(\"combined_regular_with_ssurgo_nhd_2.5kmX2.5km_part\" + str(part))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-profit",
   "metadata": {},
   "source": [
    "# In a similar fasion, you can feature engineer the waterbodies (I will get that later today/tomorrow and push the updated dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_pickle(\"combined_regular_with_ssurgo_nhd_2.5kmX2.5km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-sense",
   "metadata": {},
   "source": [
    "# This is where you would start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"combined_regular_with_ssurgo_nhd_2.5kmX2.5km\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-cleanup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
