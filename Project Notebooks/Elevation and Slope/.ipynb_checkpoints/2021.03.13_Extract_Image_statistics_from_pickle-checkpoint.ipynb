{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "insured-commitment",
   "metadata": {},
   "source": [
    "# Define the patch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "systematic-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "finnish-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 500 # 100 or 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "handy-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv file with SSURGO variables\n",
    "df_m = pd.read_csv(\"combined_regular_clean_with_ssurgo_variables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "better-speech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'jurisdiction_type', 'da_number',\n",
       "       'district', 'project_name', 'longitude', 'latitude',\n",
       "       'date_issued_or_denied', 'rha_determination', 'cwa_determination',\n",
       "       'rha1', 'rha2', 'cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6', 'cwa7',\n",
       "       'cwa8', 'cwa9', 'potential_wetland', 'index', 'Index', 'mukey',\n",
       "       'hydclprs', 'aws025wta', 'drclassdcd', 'elevation_stats_1000m',\n",
       "       'slope_stats_1000m', 'seasonality_stats_1000m',\n",
       "       'recurrence_stats_1000m', 'transition_hist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "df = []\n",
    "\n",
    "for i in range(df_m.shape[0] // 500 + 1):\n",
    "    try:\n",
    "        df_temp = pd.read_pickle(('1000m_SRTM/image_stats_' + str(2 * PATCH_SIZE) + \"X\" + str(2 * PATCH_SIZE) + '_part' + \n",
    "                              str(500 * i + 1)))\n",
    "        \n",
    "    except:\n",
    "        break\n",
    "    df.append(df_temp)\n",
    "df = pd.concat(df)\n",
    "\n",
    "\n",
    "df.rename(columns={\"srtm_stats\" : \"elevation_stats_\" + str(2 * PATCH_SIZE) + \"m\",\n",
    "                  \"slope_stats\" : \"slope_stats_\" + str(2 * PATCH_SIZE) + \"m\",\n",
    "                  \"seasonality_stats\" : \"seasonality_stats_\" + str(2 * PATCH_SIZE) + \"m\",\n",
    "                  \"recurrence_stats\" : \"recurrence_stats_\" + str(2 * PATCH_SIZE) + \"m\",}, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "designing-deficit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14619, 34)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "obvious-freeze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'jurisdiction_type', 'da_number',\n",
       "       'district', 'project_name', 'longitude', 'latitude',\n",
       "       'date_issued_or_denied', 'rha_determination', 'cwa_determination',\n",
       "       'rha1', 'rha2', 'cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6', 'cwa7',\n",
       "       'cwa8', 'cwa9', 'potential_wetland', 'index', 'Index', 'mukey',\n",
       "       'hydclprs', 'aws025wta', 'drclassdcd', 'elevation_stats_1000m',\n",
       "       'slope_stats_1000m', 'seasonality_stats_1000m',\n",
       "       'recurrence_stats_1000m', 'transition_hist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# df = pd.read_pickle('ImageStatsPickledFiles/image_stats_' + str(2 * PATCH_SIZE) + \"X\" + str(2 * PATCH_SIZE) + '_part1')\n",
    "\n",
    "\n",
    "\n",
    "df.rename(columns={\"srtm_stats\" : \"elevation_stats_\" + str(2 * PATCH_SIZE) + \"m\",\n",
    "                  \"slope_stats\" : \"slope_stats_\" + str(2 * PATCH_SIZE) + \"m\",\n",
    "                  \"seasonality_stats\" : \"seasonality_stats_\" + str(2 * PATCH_SIZE) + \"m\",\n",
    "                  \"recurrence_stats\" : \"recurrence_stats_\" + str(2 * PATCH_SIZE) + \"m\",}, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rubber-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(feature_tuple, feature):\n",
    "    mean = feature_tuple[0][feature]\n",
    "    stdev = feature_tuple[1][feature]\n",
    "    maximum = feature_tuple[2][feature + \"_max\"]\n",
    "    minimum = feature_tuple[2][feature + \"_min\"]    \n",
    "    return mean, stdev, maximum, minimum\n",
    "    \n",
    "# extract_features(df.elevation_stats_200m[0], \"elevation\")\n",
    "# extract_features(df.slope_stats_200m[0], \"slope\")\n",
    "# extract_features(df.seasonality_stats_200m[0], \"seasonality\")\n",
    "# extract_features(df.recurrence_stats_200m[0], \"recurrence\")\n",
    "# # extract_features(df.transition_stats[0], \"transition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-owner",
   "metadata": {},
   "source": [
    "## Extract image statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tracked-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [\"elevation\", \"slope\", \"seasonality\", \"recurrence\"]:\n",
    "    df[feature + \"_mean_\" + str(2 * PATCH_SIZE) + \"m\"] = (df.apply(lambda x:\n",
    "                                                                 extract_features(x[feature + \"_stats_\" \n",
    "                                                                                    + str(2 * PATCH_SIZE) \n",
    "                                                                                    + \"m\"], feature)[0],\n",
    "                                                                   axis=1\n",
    "                                                                  ))\n",
    "                                                                 \n",
    "    df[feature + \"_stdev_\" + str(2 * PATCH_SIZE) + \"m\"] = (df.apply(lambda x:\n",
    "                                                                 extract_features(x[feature + \"_stats_\" \n",
    "                                                                                    + str(2 * PATCH_SIZE) \n",
    "                                                                                    + \"m\"], feature)[1],\n",
    "                                                                   axis=1\n",
    "                                                                  ))\n",
    "                                                                 \n",
    "    df[feature + \"_max_\" + str(2 * PATCH_SIZE) + \"m\"] = (df.apply(lambda x:\n",
    "                                                                 extract_features(x[feature + \"_stats_\" \n",
    "                                                                                    + str(2 * PATCH_SIZE) \n",
    "                                                                                    + \"m\"], feature)[2],\n",
    "                                                                   axis=1\n",
    "                                                                  ))\n",
    "                                                                 \n",
    "    df[feature + \"_min_\" + str(2 * PATCH_SIZE) + \"m\"] = (df.apply(lambda x:\n",
    "                                                                 extract_features(x[feature + \"_stats_\" \n",
    "                                                                                    + str(2 * PATCH_SIZE) \n",
    "                                                                                    + \"m\"], feature)[3],\n",
    "                                                                   axis=1\n",
    "                                                                  ))\n",
    "                                                                 \n",
    "                                                                 \n",
    "                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-drill",
   "metadata": {},
   "source": [
    "## Extract transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "commercial-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    df[\"transition_\" + str(i) + \"_\" + str(2 * PATCH_SIZE) + \"m\"] = df.apply(lambda x:\n",
    "                                                                           x.transition_hist.get(str(i)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bright-central",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'jurisdiction_type', 'da_number',\n",
       "       'district', 'project_name', 'longitude', 'latitude',\n",
       "       'date_issued_or_denied', 'rha_determination', 'cwa_determination',\n",
       "       'rha1', 'rha2', 'cwa1', 'cwa2', 'cwa3', 'cwa4', 'cwa5', 'cwa6', 'cwa7',\n",
       "       'cwa8', 'cwa9', 'potential_wetland', 'index', 'Index', 'mukey',\n",
       "       'hydclprs', 'aws025wta', 'drclassdcd', 'elevation_stats_1000m',\n",
       "       'slope_stats_1000m', 'seasonality_stats_1000m',\n",
       "       'recurrence_stats_1000m', 'transition_hist', 'elevation_mean_1000m',\n",
       "       'elevation_stdev_1000m', 'elevation_max_1000m', 'elevation_min_1000m',\n",
       "       'slope_mean_1000m', 'slope_stdev_1000m', 'slope_max_1000m',\n",
       "       'slope_min_1000m', 'seasonality_mean_1000m', 'seasonality_stdev_1000m',\n",
       "       'seasonality_max_1000m', 'seasonality_min_1000m',\n",
       "       'recurrence_mean_1000m', 'recurrence_stdev_1000m',\n",
       "       'recurrence_max_1000m', 'recurrence_min_1000m', 'transition_0_1000m',\n",
       "       'transition_1_1000m', 'transition_2_1000m', 'transition_3_1000m',\n",
       "       'transition_4_1000m', 'transition_5_1000m', 'transition_6_1000m',\n",
       "       'transition_7_1000m', 'transition_8_1000m', 'transition_9_1000m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "designed-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the dataframe \n",
    "pickle.dump(df, open(\"df_srtm_slope_variables_\" + str(2*PATCH_SIZE) + \"m\", \"wb\"), protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-diving",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
