{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hearing-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import ee\n",
    "import pickle\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "innovative-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-pressure",
   "metadata": {},
   "source": [
    "# Set up bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "behind-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(lat=45.475649, lon=-69.471018, size=100):\n",
    "  crs_proj = \"EPSG:4326\"  \n",
    "  return ee.Geometry.Point([lon, lat], proj=crs_proj).buffer(size).bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "vital-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "srtm = ee.Image('USGS/SRTMGL1_003')\n",
    "slope = ee.Terrain.slope(srtm)\n",
    "jrc = ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\").select(\"seasonality\", \"recurrence\")\n",
    "\n",
    "def get_stats(image=ee.Image('USGS/SRTMGL1_003'), lat=45.475649, lon=-69.471018, size=100):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        mean = image.reduceRegion(\n",
    "                reducer = ee.Reducer.mean(),\n",
    "                geometry = square(lat, lon, size),\n",
    "                scale = 30,\n",
    "                maxPixels = 1e9\n",
    "            ).getInfo()\n",
    "\n",
    "        stdDev = image.reduceRegion(\n",
    "                reducer = ee.Reducer.stdDev(),\n",
    "                geometry = square(lat, lon, size),\n",
    "                scale = 30,\n",
    "                maxPixels = 1e9\n",
    "            ).getInfo()#.get('elevation')\n",
    "\n",
    "        maxMin = image.reduceRegion(\n",
    "                reducer = ee.Reducer.minMax(),\n",
    "                geometry = square(lat, lon, size),\n",
    "                scale = 30,\n",
    "                maxPixels = 1e9\n",
    "        ).getInfo()\n",
    "        return mean, stdDev, maxMin\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_transition(lat=45.475649, lon=-69.471018, size=100):\n",
    "    try:\n",
    "        result = ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\").select(\"transition\").reduceRegion(\n",
    "                    reducer = ee.Reducer.frequencyHistogram(),\n",
    "                    geometry = square(lat, lon, size),\n",
    "                    scale = 30,\n",
    "                    maxPixels = 1e9\n",
    "            ).getInfo()\n",
    "        return result.get('transition')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excited-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv file \n",
    "# df_m = pd.read_csv(\"combined_regular_clean_with_ssurgo_variables.csv\")\n",
    "df_m = pd.read_pickle(\"cwr_nwpr_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hungarian-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_stats(df_m_, i, size):\n",
    "\n",
    "  df_m_[\"srtm_stats\"] = (df_m_.apply(lambda x: \n",
    "                                      get_stats(image=ee.Image('USGS/SRTMGL1_003'),\n",
    "                                                lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "  df_m_[\"slope_stats\"] = (df_m_.apply(lambda x: \n",
    "                                      get_stats(image = ee.Terrain.slope(ee.Image('USGS/SRTMGL1_003')),\n",
    "                                                lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "\n",
    "  df_m_[\"seasonality_stats\"] = (df_m_.apply(lambda x: \n",
    "                                      get_stats(image=ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\").select(\"seasonality\"),\n",
    "                                                lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "\n",
    "  df_m_[\"recurrence_stats\"] = (df_m_.apply(lambda x: \n",
    "                                      get_stats(image=ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\").select(\"recurrence\"),\n",
    "                                                lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "    \n",
    "\n",
    "  df_m_[\"transition_hist\"] = (df_m_.apply(lambda x: \n",
    "                                      get_transition(lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "  \n",
    "  # pickle the dataframe \n",
    "  (pickle.dump(df_m_, open(\"cwr_nwpr/\" + str(2 * PATCH_SIZE) + \"m_SRTM/image_stats_\" \n",
    "                           + str(2*PATCH_SIZE) + \"X\" + str(2*PATCH_SIZE)\n",
    "                           + \"_part\" + str(i),\"wb\"), \n",
    "               protocol=3))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "broke-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 19:45:36.551337\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "wound-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1 of 10 started\n",
      "batch 1 of 10 done\n",
      "batch 2 of 10 started\n",
      "batch 2 of 10 done\n",
      "batch 3 of 10 started\n",
      "batch 3 of 10 done\n",
      "batch 4 of 10 started\n",
      "batch 4 of 10 done\n",
      "batch 5 of 10 started\n",
      "batch 5 of 10 done\n",
      "batch 6 of 10 started\n",
      "batch 6 of 10 done\n",
      "batch 7 of 10 started\n",
      "batch 7 of 10 done\n",
      "batch 8 of 10 started\n",
      "batch 8 of 10 done\n",
      "batch 9 of 10 started\n",
      "batch 9 of 10 done\n",
      "batch 10 of 10 started\n",
      "batch 10 of 10 done\n"
     ]
    }
   ],
   "source": [
    "# pass in batches of 500\n",
    "# MADHUKAR: 0 - 5000 \n",
    "# SHOBHA: 5000 - 10000\n",
    "# RADHIKA: 10000 - 15000\n",
    "\n",
    "patch_size = PATCH_SIZE\n",
    "batch_size = 50\n",
    "MY_NAME = \"MADHUKAR\"\n",
    "START = 0 + 5000 * (MY_NAME == \"SHOBHA\") + 10000 * (MY_NAME == \"RADHIKA\")\n",
    "\n",
    "for batch in range(10,65):\n",
    "  print(\"batch {} of 10 started\".format(batch + 1))\n",
    "  batch_df = df_m[START + batch_size * batch : START + batch_size * (batch + 1)].copy()\n",
    "  extract_image_stats(batch_df, (START + batch_size * batch) + 1, size = patch_size)\n",
    "  print(\"batch {} of 10 done\".format(batch + 1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "blind-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pass in batches of 500\n",
    "# # MADHUKAR: 0 - 5000 \n",
    "# # SHOBHA: 5000 - 10000\n",
    "# # RADHIKA: 10000 - 15000\n",
    "\n",
    "# patch_size = PATCH_SIZE\n",
    "# batch_size = 500\n",
    "# MY_NAME = \"SHOBHA\"\n",
    "# START = 0 + 5000 * (MY_NAME == \"SHOBHA\") + 10000 * (MY_NAME == \"RADHIKA\")\n",
    "\n",
    "# for batch in range(10):\n",
    "#   print(\"batch {} of 10 started\".format(batch + 1))\n",
    "#   batch_df = df_m[START + batch_size * batch : START + batch_size * (batch + 1)].copy()\n",
    "#   extract_image_stats(batch_df, (START + batch_size * batch) + 1, size = patch_size)\n",
    "#   print(\"batch {} of 10 done\".format(batch + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "vertical-moscow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 6 of 10 batches done\n",
    "\n",
    "# patch_size = PATCH_SIZE\n",
    "# batch_size = 500\n",
    "# MY_NAME = \"RADHIKA\"\n",
    "# START = 0 + 5000 * (MY_NAME == \"SHOBHA\") + 10000 * (MY_NAME == \"RADHIKA\")\n",
    "\n",
    "# for batch in range(6, 10):\n",
    "#   print(\"batch {} of 10 started\".format(batch + 1))\n",
    "#   batch_df = df_m[START + batch_size * batch : START + batch_size * (batch + 1)].copy()\n",
    "#   extract_image_stats(batch_df, (START + batch_size * batch) + 1, size = patch_size)\n",
    "#   print(\"batch {} of 10 done\".format(batch + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "varying-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 20:05:43.826310\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "breathing-tennis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jurisdiction_type', 'da_number', 'latitude', 'longitude',\n",
       "       'cwa_determination', 'Index', 'srtm_stats', 'slope_stats',\n",
       "       'seasonality_stats', 'recurrence_stats', 'transition_hist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m_test = pd.read_pickle(\"cwr_nwpr/\" + str(2 * PATCH_SIZE) + \"m_SRTM/image_stats_\" + str(2 * PATCH_SIZE) + \"X\" + str(2 * PATCH_SIZE) + \"_part1\")\n",
    "df_m_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "continuous-conflict",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'2': 1.9725490196078432, '5': 1.7058823529411766}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'10': 0.6862745098039216}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'5': 1}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'1': 13.839215686274507, '10': 1.6, '2': 2, '4': 0.2823529411764706, '5': 4.580392156862745, '6': 2, '8': 0.1411764705882353}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'1': 14.541176470588233, '4': 3.266666666666667, '5': 7.349019607843137, '6': 8.298039215686273}\n",
      "{}\n",
      "{}\n",
      "{'10': 1.211764705882353}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'1': 2.9176470588235293, '5': 5.537254901960785, '6': 0.14901960784313725, '7': 2.768627450980392}\n",
      "{'5': 1}\n",
      "{}\n",
      "{'5': 0.8980392156862745}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "for item in df_m_test.transition_hist:\n",
    "    print(item)\n",
    "# df_m_test.image_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-quantity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
