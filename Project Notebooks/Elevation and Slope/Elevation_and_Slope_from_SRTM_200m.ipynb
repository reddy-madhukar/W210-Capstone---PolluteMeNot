{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hearing-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import ee\n",
    "import pickle\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "innovative-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-pressure",
   "metadata": {},
   "source": [
    "# Set up bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "behind-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(lat=45.475649, lon=-69.471018, size=100):\n",
    "  crs_proj = \"EPSG:4326\"  \n",
    "  return ee.Geometry.Point([lon, lat], proj=crs_proj).buffer(size).bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vital-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "srtm = ee.Image('USGS/SRTMGL1_003')\n",
    "slope = ee.Terrain.slope(srtm)\n",
    "jrc = ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\").select(\"seasonality\", \"recurrence\")\n",
    "\n",
    "def get_stats(image=ee.Image('USGS/SRTMGL1_003'), lat=45.475649, lon=-69.471018, size=100):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        mean = image.reduceRegion(\n",
    "                reducer = ee.Reducer.mean(),\n",
    "                geometry = square(lat, lon, size),\n",
    "                scale = 30,\n",
    "                maxPixels = 1e9\n",
    "            ).getInfo()\n",
    "\n",
    "        stdDev = image.reduceRegion(\n",
    "                reducer = ee.Reducer.stdDev(),\n",
    "                geometry = square(lat, lon, size),\n",
    "                scale = 30,\n",
    "                maxPixels = 1e9\n",
    "            ).getInfo()#.get('elevation')\n",
    "\n",
    "        maxMin = image.reduceRegion(\n",
    "                reducer = ee.Reducer.minMax(),\n",
    "                geometry = square(lat, lon, size),\n",
    "                scale = 30,\n",
    "                maxPixels = 1e9\n",
    "        ).getInfo()\n",
    "        return mean, stdDev, maxMin\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_transition(lat=45.475649, lon=-69.471018, size=100):\n",
    "    try:\n",
    "        result = ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\").select(\"transition\").reduceRegion(\n",
    "                    reducer = ee.Reducer.frequencyHistogram(),\n",
    "                    geometry = square(lat, lon, size),\n",
    "                    scale = 30,\n",
    "                    maxPixels = 1e9\n",
    "            ).getInfo()\n",
    "        return result.get('transition')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excited-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv file \n",
    "# df_m = pd.read_csv(\"combined_regular_clean_with_ssurgo_variables.csv\")\n",
    "df_m = pd.read_pickle(\"cwr_nwpr_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hungarian-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_stats(df_m_, i, size):\n",
    "\n",
    "  df_m_[\"srtm_stats\"] = (df_m_.apply(lambda x: \n",
    "                                      get_stats(image=ee.Image('USGS/SRTMGL1_003'),\n",
    "                                                lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "  df_m_[\"slope_stats\"] = (df_m_.apply(lambda x: \n",
    "                                      get_stats(image = ee.Terrain.slope(ee.Image('USGS/SRTMGL1_003')),\n",
    "                                                lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "\n",
    "  df_m_[\"seasonality_stats\"] = (df_m_.apply(lambda x: \n",
    "                                      get_stats(image=ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\").select(\"seasonality\"),\n",
    "                                                lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "\n",
    "  df_m_[\"recurrence_stats\"] = (df_m_.apply(lambda x: \n",
    "                                      get_stats(image=ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\").select(\"recurrence\"),\n",
    "                                                lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "    \n",
    "\n",
    "  df_m_[\"transition_hist\"] = (df_m_.apply(lambda x: \n",
    "                                      get_transition(lat=x.latitude, \n",
    "                                                lon=x.longitude, \n",
    "                                                size=size), \n",
    "                                      axis=1))\n",
    "  \n",
    "  # pickle the dataframe \n",
    "  (pickle.dump(df_m_, open(\"cwr_nwpr/\" + str(2 * PATCH_SIZE) + \"m_SRTM/image_stats_\" \n",
    "                           + str(2*PATCH_SIZE) + \"X\" + str(2*PATCH_SIZE)\n",
    "                           + \"_part\" + str(i),\"wb\"), \n",
    "               protocol=3))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "broke-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-03 01:33:23.063522\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wound-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 11 of 10 started\n",
      "batch 11 of 10 done\n",
      "batch 12 of 10 started\n",
      "batch 12 of 10 done\n",
      "batch 13 of 10 started\n",
      "batch 13 of 10 done\n",
      "batch 14 of 10 started\n",
      "batch 14 of 10 done\n",
      "batch 15 of 10 started\n",
      "batch 15 of 10 done\n",
      "batch 16 of 10 started\n",
      "batch 16 of 10 done\n",
      "batch 17 of 10 started\n",
      "batch 17 of 10 done\n",
      "batch 18 of 10 started\n",
      "batch 18 of 10 done\n",
      "batch 19 of 10 started\n",
      "batch 19 of 10 done\n",
      "batch 20 of 10 started\n",
      "batch 20 of 10 done\n",
      "batch 21 of 10 started\n",
      "batch 21 of 10 done\n",
      "batch 22 of 10 started\n",
      "batch 22 of 10 done\n",
      "batch 23 of 10 started\n",
      "batch 23 of 10 done\n",
      "batch 24 of 10 started\n",
      "batch 24 of 10 done\n",
      "batch 25 of 10 started\n",
      "batch 25 of 10 done\n",
      "batch 26 of 10 started\n",
      "batch 26 of 10 done\n",
      "batch 27 of 10 started\n",
      "batch 27 of 10 done\n",
      "batch 28 of 10 started\n",
      "batch 28 of 10 done\n",
      "batch 29 of 10 started\n",
      "batch 29 of 10 done\n",
      "batch 30 of 10 started\n",
      "batch 30 of 10 done\n",
      "batch 31 of 10 started\n",
      "batch 31 of 10 done\n",
      "batch 32 of 10 started\n",
      "batch 32 of 10 done\n",
      "batch 33 of 10 started\n",
      "batch 33 of 10 done\n",
      "batch 34 of 10 started\n",
      "batch 34 of 10 done\n",
      "batch 35 of 10 started\n",
      "batch 35 of 10 done\n",
      "batch 36 of 10 started\n",
      "batch 36 of 10 done\n",
      "batch 37 of 10 started\n",
      "batch 37 of 10 done\n",
      "batch 38 of 10 started\n",
      "batch 38 of 10 done\n",
      "batch 39 of 10 started\n",
      "batch 39 of 10 done\n",
      "batch 40 of 10 started\n",
      "batch 40 of 10 done\n",
      "batch 41 of 10 started\n",
      "batch 41 of 10 done\n",
      "batch 42 of 10 started\n",
      "batch 42 of 10 done\n",
      "batch 43 of 10 started\n",
      "batch 43 of 10 done\n",
      "batch 44 of 10 started\n",
      "batch 44 of 10 done\n",
      "batch 45 of 10 started\n",
      "batch 45 of 10 done\n",
      "batch 46 of 10 started\n",
      "batch 46 of 10 done\n",
      "batch 47 of 10 started\n",
      "batch 47 of 10 done\n",
      "batch 48 of 10 started\n",
      "batch 48 of 10 done\n",
      "batch 49 of 10 started\n",
      "batch 49 of 10 done\n",
      "batch 50 of 10 started\n",
      "batch 50 of 10 done\n",
      "batch 51 of 10 started\n",
      "batch 51 of 10 done\n",
      "batch 52 of 10 started\n",
      "batch 52 of 10 done\n",
      "batch 53 of 10 started\n",
      "batch 53 of 10 done\n",
      "batch 54 of 10 started\n",
      "batch 54 of 10 done\n",
      "batch 55 of 10 started\n",
      "batch 55 of 10 done\n",
      "batch 56 of 10 started\n",
      "batch 56 of 10 done\n",
      "batch 57 of 10 started\n",
      "batch 57 of 10 done\n",
      "batch 58 of 10 started\n",
      "batch 58 of 10 done\n",
      "batch 59 of 10 started\n",
      "batch 59 of 10 done\n",
      "batch 60 of 10 started\n",
      "batch 60 of 10 done\n",
      "batch 61 of 10 started\n",
      "batch 61 of 10 done\n",
      "batch 62 of 10 started\n",
      "batch 62 of 10 done\n",
      "batch 63 of 10 started\n",
      "batch 63 of 10 done\n",
      "batch 64 of 10 started\n",
      "batch 64 of 10 done\n",
      "batch 65 of 10 started\n",
      "batch 65 of 10 done\n"
     ]
    }
   ],
   "source": [
    "# pass in batches of 500\n",
    "# MADHUKAR: 0 - 5000 \n",
    "# SHOBHA: 5000 - 10000\n",
    "# RADHIKA: 10000 - 15000\n",
    "\n",
    "patch_size = PATCH_SIZE\n",
    "batch_size = 50\n",
    "MY_NAME = \"MADHUKAR\"\n",
    "START = 0 + 5000 * (MY_NAME == \"SHOBHA\") + 10000 * (MY_NAME == \"RADHIKA\")\n",
    "\n",
    "for batch in range(10,65):\n",
    "  print(\"batch {} of 10 started\".format(batch + 1))\n",
    "  batch_df = df_m[START + batch_size * batch : START + batch_size * (batch + 1)].copy()\n",
    "  extract_image_stats(batch_df, (START + batch_size * batch) + 1, size = patch_size)\n",
    "  print(\"batch {} of 10 done\".format(batch + 1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blind-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pass in batches of 500\n",
    "# # MADHUKAR: 0 - 5000 \n",
    "# # SHOBHA: 5000 - 10000\n",
    "# # RADHIKA: 10000 - 15000\n",
    "\n",
    "# patch_size = PATCH_SIZE\n",
    "# batch_size = 500\n",
    "# MY_NAME = \"SHOBHA\"\n",
    "# START = 0 + 5000 * (MY_NAME == \"SHOBHA\") + 10000 * (MY_NAME == \"RADHIKA\")\n",
    "\n",
    "# for batch in range(10):\n",
    "#   print(\"batch {} of 10 started\".format(batch + 1))\n",
    "#   batch_df = df_m[START + batch_size * batch : START + batch_size * (batch + 1)].copy()\n",
    "#   extract_image_stats(batch_df, (START + batch_size * batch) + 1, size = patch_size)\n",
    "#   print(\"batch {} of 10 done\".format(batch + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vertical-moscow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 6 of 10 batches done\n",
    "\n",
    "# patch_size = PATCH_SIZE\n",
    "# batch_size = 500\n",
    "# MY_NAME = \"RADHIKA\"\n",
    "# START = 0 + 5000 * (MY_NAME == \"SHOBHA\") + 10000 * (MY_NAME == \"RADHIKA\")\n",
    "\n",
    "# for batch in range(6, 10):\n",
    "#   print(\"batch {} of 10 started\".format(batch + 1))\n",
    "#   batch_df = df_m[START + batch_size * batch : START + batch_size * (batch + 1)].copy()\n",
    "#   extract_image_stats(batch_df, (START + batch_size * batch) + 1, size = patch_size)\n",
    "#   print(\"batch {} of 10 done\".format(batch + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "varying-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-03 03:11:39.279832\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "breathing-tennis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jurisdiction_type', 'da_number', 'latitude', 'longitude',\n",
       "       'cwa_determination', 'Index', 'srtm_stats', 'slope_stats',\n",
       "       'seasonality_stats', 'recurrence_stats', 'transition_hist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m_test = pd.read_pickle(\"cwr_nwpr/\" + str(2 * PATCH_SIZE) + \"m_SRTM/image_stats_\" + str(2 * PATCH_SIZE) + \"X\" + str(2 * PATCH_SIZE) + \"_part1\")\n",
    "df_m_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continuous-conflict",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'2': 1.9725490196078432, '5': 1.7058823529411766}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'10': 0.6862745098039216}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'5': 1}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'1': 13.839215686274507, '10': 1.6, '2': 2, '4': 0.2823529411764706, '5': 4.580392156862745, '6': 2, '8': 0.1411764705882353}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'1': 14.541176470588233, '4': 3.266666666666667, '5': 7.349019607843137, '6': 8.298039215686273}\n",
      "{}\n",
      "{}\n",
      "{'10': 1.211764705882353}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'1': 2.9176470588235293, '5': 5.537254901960785, '6': 0.14901960784313725, '7': 2.768627450980392}\n",
      "{'5': 1}\n",
      "{}\n",
      "{'5': 0.8980392156862745}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "for item in df_m_test.transition_hist:\n",
    "    print(item)\n",
    "# df_m_test.image_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-quantity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
